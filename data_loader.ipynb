{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цикличный загрузчик данных по папке в одну таблицу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Реализованный функционал:\n",
    "- Считывание файлов из папки.\n",
    "- Перед загрузкой просматривать файл на ошибки в разметке столбцов. По возможности логировать этот процесс.\n",
    "- Загрузка файлов в указанную таблицу.\n",
    "___\n",
    "Развитие:\n",
    "- Рассмотреть возможность загрузки файлов из локальной папки или из HDFS.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import contextlib\n",
    "\n",
    "import ibis \n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from hdfs.ext.kerberos import KerberosClient\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket cache: FILE:/tmp/krb5cc\n",
      "Default principal: gpbu16371@INT.GAZPROMBANK.RU\n",
      "\n",
      "Valid starting       Expires              Service principal\n",
      "07/01/2021 12:40:11  07/01/2021 22:40:11  krbtgt/INT.GAZPROMBANK.RU@INT.GAZPROMBANK.RU\n",
      "\trenew until 07/08/2021 12:40:11\n",
      "Ticket cache: FILE:/tmp/krb5cc\n",
      "Default principal: gpbu16371@INT.GAZPROMBANK.RU\n",
      "\n",
      "Valid starting       Expires              Service principal\n",
      "07/01/2021 12:40:29  07/01/2021 22:40:29  krbtgt/INT.GAZPROMBANK.RU@INT.GAZPROMBANK.RU\n",
      "\trenew until 07/08/2021 12:40:29\n"
     ]
    }
   ],
   "source": [
    "# Получение нового тикета доступа\n",
    "login = 'gpbu16371'\n",
    "password = '***'\n",
    "!klist\n",
    "\n",
    "os.system('echo ' + password + ' | kinit ' + login)\n",
    "!klist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Папка, из которой мы загружаем файлы\n",
    "folder = '/work/data_loader/20210603_fraud'\n",
    "\n",
    "# База, в которую грузим (в т.ч. временную таблицу)\n",
    "database = 'sbx_dml'\n",
    "\n",
    "# Название временной таблицы\n",
    "temp_table = 'pde_temp_ext'\n",
    "\n",
    "# Название итоговой таблицы\n",
    "table = 'pde_fraud_temp'\n",
    "\n",
    "# Разделитель в файлах\n",
    "sep = ';'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Считывание всех файлов из указанной папки\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    full_path = os.path.join(folder, file)\n",
    "    if os.path.isfile(full_path):\n",
    "        files.append(file)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало анализа: 2021-07-01 12:46:05\n",
      "Конец анализа:  2021-07-01 12:46:06\n"
     ]
    }
   ],
   "source": [
    "# Поиск строк с ошибочными разделителями\n",
    "print('Начало анализа:', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "with open('log.txt', 'w') as log:\n",
    "    # print записывает имя файла в лог\n",
    "    with contextlib.redirect_stdout(log):\n",
    "        # Если есть ошибка в разметке, она запишется в лог\n",
    "        with contextlib.redirect_stderr(log):\n",
    "            for file in sorted(files):\n",
    "                print('Файл:', file)\n",
    "                df = pd.read_csv(folder + '/' + file, sep = sep, encoding = 'Windows-1251', error_bad_lines = False, dtype = np.str)\n",
    "                \n",
    "print ('Конец анализа: ', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name, error]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем лог для анализа\n",
    "with open('log.txt', 'r') as log:\n",
    "    log_data = log.read()[:-1]\n",
    "\n",
    "log_data = log_data.replace(\"'\\nb'\", \"\")       \n",
    "log_data = log_data.replace(\"\\\\n\", \"; \")    \n",
    "    \n",
    "# Преобразуем его в DataFrame для удобства\n",
    "df_log = pd.DataFrame(log_data.split('\\n'))\n",
    "\n",
    "# Удаляем строки, по которым нет ошибок\n",
    "df_log_error = pd.concat([df_log.shift(periods = 1, fill_value = 0), df_log], axis = 1)[1:]\n",
    "df_log_error.columns = ['data', 'shift_data']\n",
    "df_log_error['shift_data_index'] = df_log_error['shift_data'].str.find('Файл')\n",
    "df_log_error = df_log_error[df_log_error['shift_data_index'] < 0]\n",
    "df_log_error.drop(['shift_data_index'], inplace = True, axis = 1)\n",
    "\n",
    "# Разбиение DataFrame в случае нескольких ошибок для одной строки\n",
    "df_log_error['shift_data'] = df_log_error['shift_data'].str[2:-3]\n",
    "df_log_error = df_log_error.set_index(['data']).apply(lambda x: x.str.split('; ').explode()).reset_index()\n",
    "df_log_error['data'] = df_log_error['data'].str.replace('Файл: ', '')\n",
    "df_log_error.columns = ['file_name', 'error']\n",
    "\n",
    "df_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало загрузки: 2021-07-01 12:46:10, файл: 1. fraud 21y.csv\n",
      "Считано записей: 6462\n",
      "Without an HDFS connection, certain functionality may be disabled\n",
      "Начало загрузки: 2021-07-01 12:46:30, файл: 2. fraud_100 (1).csv\n",
      "Считано записей: 69658\n",
      "Without an HDFS connection, certain functionality may be disabled\n"
     ]
    }
   ],
   "source": [
    "for index, file in enumerate(sorted(files), 1):\n",
    "    # Вывод даты начала загрузки\n",
    "    start = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print('Начало загрузки: ' + start + ', файл: ' + str(index) + \". \" + file)\n",
    "\n",
    "    # Загрузка файла в память\n",
    "    df_for_load = pd.read_csv(folder + '/' + file, sep = sep, encoding = 'Windows-1251', dtype = np.str)\n",
    "    df_for_load['file_name'] = file\n",
    "\n",
    "\n",
    "    # Сколько записей считано в файле\n",
    "    print('Считано записей: ' + str(df_for_load.shape[0]))\n",
    "\n",
    "    # Подключение к БД для запросов\n",
    "    conn = connect(host = 'hdp-p3pml', \n",
    "                   port = 21050,  \n",
    "                   use_ssl = 'true', \n",
    "                   auth_mechanism = 'GSSAPI',\n",
    "                   database = database)\n",
    "    cursor = conn.cursor()  \n",
    "    cursor.execute(\"Drop Table If Exists \" + database + \".\" + temp_table)\n",
    "\n",
    "    # Загрузка данных во временную таблицу\n",
    "    file_schema = ibis.expr.schema.infer(df_for_load)\n",
    "    db_name = database\n",
    "    table_name = temp_table\n",
    "    impala_tbl_folder = '/data/sbx/' + database[database.find(\"_\") + 1:]\n",
    "    client = ibis.impala.connect(host = 'hdp-p3pml', \n",
    "                                 port = 21050,  \n",
    "                                 use_ssl = 'true', \n",
    "                                 auth_mechanism = 'GSSAPI')\n",
    "    db = client.database(db_name)\n",
    "    db.create_table(table_name, schema = file_schema)\n",
    "    df_for_load.to_parquet(table_name + '.parq', index = False)\n",
    "    client = KerberosClient('https://hdp-p3pml:14000')\n",
    "    client.upload(impala_tbl_folder + '/' + table_name + '/', table_name + '.parq')\n",
    "    db.table(table_name).refresh()\n",
    "\n",
    "    # Реально выполняется только для первого файла (из-за IF NOT EXISTS)\n",
    "    # Создание итоговой таблицы, структура которой соотвествует структуре временной\n",
    "    query = ''\n",
    "\n",
    "    cursor.execute(\"SHOW CREATE TABLE \" + database + '.' + temp_table)\n",
    "    query_result = cursor.fetchall()\n",
    "    for string in query_result:\n",
    "        str_beg = string[0].find('(')             # Оставляем запрос, начиная с первой скобки\n",
    "        str_end = string[0].find('PARQUET') + 7   # Обрезаем запрос до конца PARQUET\n",
    "        query += \"CREATE TABLE IF NOT EXISTS \" + database + '.' + table + \" \" + string[0][str_beg:str_end].replace('  ', '\\t')\n",
    "\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Перенос данных из временной таблицы\n",
    "    cursor.execute(\"Insert Into \" + database + \".\" + table + \" Select * From \" + database + \".\" + temp_table)\n",
    "\n",
    "    del df_for_load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
