{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Парсинг строк DM SmartLog (Created By E.S. Kopylov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Евгений', 27, 'Аналитик данных']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Имя', 'Возраст', 'Должность']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slovar = {'Имя':'Евгений', 'Возраст':27, 'Должность':'Аналитик данных'}\n",
    "\n",
    "display(list(slovar.values()))\n",
    "\n",
    "display(list(slovar.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04-11-25\n"
     ]
    }
   ],
   "source": [
    "from datetime import *\n",
    "\n",
    "choose_date =  (date.today() - timedelta(days=1)).strftime('%d-%m-%y')\n",
    "print(choose_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0                              1               2     3      4      5  \\\n",
      "0    dqcs         dq_internal_dependency  d1sasetl_admin  None   True  False   \n",
      "1    dqcs         dq_external_dependency  d1sasetl_admin  None   True  False   \n",
      "2    dqcs             dq_check_parameter  d1sasetl_admin  None   True  False   \n",
      "3    dqcs         dq_balance_load_report  d1sasetl_admin  None   True  False   \n",
      "4    dqcs  dq_agr_balance_det_evd_report  d1sasetl_admin  None   True  False   \n",
      "..    ...                            ...             ...   ...    ...    ...   \n",
      "653   tpl               fw_object_status  d1sasetl_admin  None  False  False   \n",
      "654   tpl           fw_object_dependency  d1sasetl_admin  None   True  False   \n",
      "655   tpl             fw_object_metadata  d1sasetl_admin  None  False  False   \n",
      "656   tpl                  fw_object_log  d1sasetl_admin  None  False  False   \n",
      "657   tpl                    fw_flow_log  d1sasetl_admin  None  False  False   \n",
      "\n",
      "         6      7  \n",
      "0    False  False  \n",
      "1    False  False  \n",
      "2    False  False  \n",
      "3    False  False  \n",
      "4    False  False  \n",
      "..     ...    ...  \n",
      "653  False  False  \n",
      "654  False  False  \n",
      "655  False  False  \n",
      "656  False  False  \n",
      "657  False  False  \n",
      "\n",
      "[658 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------ вытаскиваем нужные нам метрики из Cloudera Manager -------------------------------\n",
    "connection = psycopg2.connect(database=\"d1sasetl\", user='dl_monitor', password='hMDfQgwChmVFVU2wZwqK', host=\"dtf-p3pgl-n1\", port=5432)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "sql_context = (\n",
    "'''\n",
    "SELECT *\n",
    "FROM pg_catalog.pg_tables\n",
    "ORDER BY schemaname\n",
    "'''\n",
    ")\n",
    "\n",
    "cursor.execute(sql_context)\n",
    "\n",
    "df_stat = pd.DataFrame(cursor.fetchall())\n",
    "print(df_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['hdfs', 'dfs', '-count', '-q', '/data/sbx/041/']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43c0c7e74688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshell_comand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hdfs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dfs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-count'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/data/sbx/041/'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#shell_comand = subprocess.check_output(['hdfs', 'dfs', '-count', '-q', '/data/sbx/041'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 336\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 418\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['hdfs', 'dfs', '-count', '-q', '/data/sbx/041/']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#hdfs dfs -du -s -h /data/sbx/041/dm_evd.root_agreement_loan\n",
    "import subprocess\n",
    "\n",
    "shell_comand = subprocess.check_output(['hdfs', 'dfs', '-count', '-q', '/data/sbx/041/'])\n",
    "#shell_comand = subprocess.check_output(['hdfs', 'dfs', '-count', '-q', '/data/sbx/041'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполняем в поледнюю очередь! Планировщик для ежедневных выгрузок "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Начало выполнения запроса: 2021-12-03 07:53:05\n",
      "\n",
      "\n",
      "Конец выполнения запроса: 2021-12-03 07:53:11\n",
      "\n",
      "\u001b[1mРазмер DataFrame составляет: 5 строк\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "Объём занимаемой памяти:0.20794265 Mb\n",
      "\u001b[0m\n",
      "\n",
      "Начало отработки функции: 2021-12-03 07:53:11\n",
      "\n",
      "                                         df_words_emp  row_number  \\\n",
      "0   [добрый день клиента потеха Белгороде кому нуж...           0   \n",
      "1                                       [без понятия]           1   \n",
      "2   [наверное центральный черноземные счёт там отк...           2   \n",
      "3                                              [0:49]           3   \n",
      "4                                 [с кем связываться]           4   \n",
      "5   [а где в каком он городе то я вот не могу найт...           5   \n",
      "6   [Воронежа как показывает центральный черных за...           6   \n",
      "7                                           [угу угу]           7   \n",
      "8                   [и куда там кредитная управление]           8   \n",
      "9                                               [угу]           9   \n",
      "10  [угу понятно ну ладно сейчас будем то вы позво...          10   \n",
      "\n",
      "    df_hum_sec_emp df_hum_dttm_emp df_start_sec_emp  \n",
      "0          10349.0    00:00:10:349     00:00:01:440  \n",
      "1           9810.0    00:00:09:810     00:00:11:100  \n",
      "2           6180.0    00:00:06:180     00:00:20:160  \n",
      "3           7589.0    00:00:07:589     00:00:24:630  \n",
      "4           7920.0    00:00:07:920     00:00:31:620  \n",
      "5           8759.0    00:00:08:759     00:00:38:910  \n",
      "6          29580.0    00:00:29:580     00:00:46:950  \n",
      "7          28439.0    00:00:28:439     00:01:15:690  \n",
      "8           4379.0    00:00:04:379     00:01:43:530  \n",
      "9           5760.0    00:00:05:760     00:01:46:890  \n",
      "10          3190.0    00:00:03:190     00:01:51:990  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:348: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:354: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:356: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         df_words_emp  row_number  \\\n",
      "0                                      [здравствуйте]           0   \n",
      "1   [Татьяна знаю есть счёт накопительную называет...           1   \n",
      "2   [называется управляет процентов вот можете мен...           2   \n",
      "3                                 [8 (922) 858-09-92]           3   \n",
      "4                        [Васильева Ольга Николаевна]           4   \n",
      "5   [у меня интересует такой вопрос я в октябре по...           5   \n",
      "6   [ноября лежала меньше сумма да и вот по итогам...           6   \n",
      "7                                   [возможно Кирилл]           7   \n",
      "8   [тебе пополнял на 900000 и там получилось боль...           8   \n",
      "9                                           [то есть]           9   \n",
      "10  [так вот этот ну же пролежал в месяц почему мн...          10   \n",
      "11                                               [да]          11   \n",
      "12                          [а то есть на остаток да]          12   \n",
      "13  [и ещё второй вопрос вот там я читала правила ...          13   \n",
      "14                                              [так]          14   \n",
      "15                                               [да]          15   \n",
      "16                                              [угу]          16   \n",
      "17                                              [угу]          17   \n",
      "18                                              [угу]          18   \n",
      "19                                      [а пополнять]          19   \n",
      "20                                      [что будет 6]          20   \n",
      "21  [все спасибо значит если сумма прилегала весь ...          21   \n",
      "22                          [все большое вам спасибо]          22   \n",
      "23                         [нет не осталось все ясно]          23   \n",
      "24                                   [как называется]          24   \n",
      "25                                        [копить да]          25   \n",
      "26                                              [угу]          26   \n",
      "27             [то есть 8% за 3 месяца да получается]          27   \n",
      "28                                              [угу]          28   \n",
      "29                                              [угу]          29   \n",
      "30                                          [понятно]          30   \n",
      "31                                          [угу угу]          31   \n",
      "32                           [хорошо спасибо большое]          32   \n",
      "33                             [вот пока нет спасибо]          33   \n",
      "34                                      [до свидания]          34   \n",
      "\n",
      "    df_hum_sec_emp df_hum_dttm_emp df_start_sec_emp  \n",
      "0           2009.0    00:00:02:009     00:00:03:420  \n",
      "1           7590.0    00:00:07:590     00:00:04:740  \n",
      "2          18779.0    00:00:18:779     00:00:11:580  \n",
      "3          12689.0    00:00:12:689     00:00:20:670  \n",
      "4           5580.0    00:00:05:580     00:00:32:670  \n",
      "5          21150.0    00:00:21:150     00:00:37:680  \n",
      "6          13800.0    00:00:13:800     00:00:58:080  \n",
      "7          21810.0    00:00:21:810     00:01:11:130  \n",
      "8          44189.0    00:00:44:189     00:01:32:100  \n",
      "9           4170.0    00:00:04:170     00:02:15:660  \n",
      "10         20790.0    00:00:20:790     00:02:19:230  \n",
      "11         15719.0    00:00:15:719     00:02:39:000  \n",
      "12          7949.0    00:00:07:949     00:02:54:120  \n",
      "13         17520.0    00:00:17:520     00:03:01:470  \n",
      "14          7349.0    00:00:07:349     00:03:17:970  \n",
      "15          2700.0    00:00:02:700     00:03:24:300  \n",
      "16          7380.0    00:00:07:380     00:03:25:980  \n",
      "17          4919.0    00:00:04:919     00:03:32:340  \n",
      "18          2220.0    00:00:02:220     00:03:36:240  \n",
      "19          5939.0    00:00:05:939     00:03:37:500  \n",
      "20          3660.0    00:00:03:660     00:03:42:810  \n",
      "21         10679.0    00:00:10:679     00:03:45:720  \n",
      "22          4799.0    00:00:04:799     00:03:55:710  \n",
      "23         14459.0    00:00:14:459     00:03:59:790  \n",
      "24          4619.0    00:00:04:619     00:04:13:560  \n",
      "25          4709.0    00:00:04:709     00:04:16:950  \n",
      "26         10409.0    00:00:10:409     00:04:20:550  \n",
      "27          3719.0    00:00:03:719     00:04:24:660  \n",
      "28          3329.0    00:00:03:329     00:04:34:050  \n",
      "29          6569.0    00:00:06:569     00:04:36:750  \n",
      "30          3540.0    00:00:03:540     00:04:39:060  \n",
      "31          5699.0    00:00:05:699     00:04:44:790  \n",
      "32          1150.0    00:00:01:150     00:04:47:580  \n",
      "33             NaN             NaN     00:04:51:510  \n",
      "34             NaN             NaN     00:04:56:550  \n",
      "                                         df_words_emp  row_number  \\\n",
      "0                                             [Ирина]           0   \n",
      "1                              [здравствуйте Надежда]           1   \n",
      "2                             [я хочу карту заказать]           2   \n",
      "3                                             [можно]           3   \n",
      "4                 [да ну как новую вообще первый раз]           4   \n",
      "5                                              [алло]           5   \n",
      "6                                              [алло]           6   \n",
      "7                                         [алло алло]           7   \n",
      "8                                              [алло]           8   \n",
      "9                                           [так что]           9   \n",
      "10                            [а если есть у вас мир]          10   \n",
      "11                                        [можно мир]          11   \n",
      "12                                            [ага а]          12   \n",
      "13             [если как зарплатную то надо можно ее]          13   \n",
      "14                                   [город за духов]          14   \n",
      "15                              [кем Минская область]          15   \n",
      "16                                                [а]          16   \n",
      "17                                             [воду]          17   \n",
      "18                                              [угу]          18   \n",
      "19                                             [алло]          19   \n",
      "20                                             [алло]          20   \n",
      "21                                             [алло]          21   \n",
      "22                                              [угу]          22   \n",
      "23    [ну это Тюменская область не не осуществляется]          23   \n",
      "24                                         [в Тюмени]          24   \n",
      "25                                            [и как]          25   \n",
      "26                            [тогда мне заказать ее]          26   \n",
      "27                      [а все с банковскими то есть]          27   \n",
      "28                                              [угу]          28   \n",
      "29                                          [господи]          29   \n",
      "30  [так ну что же делать то почему нету уже доста...          30   \n",
      "31        [как бы сколько слышала говорит доставляют]          31   \n",
      "32                        [значит через чем менее да]          32   \n",
      "33                 [хорошо я подумаю спасибо большое]          33   \n",
      "\n",
      "    df_hum_sec_emp df_hum_dttm_emp df_start_sec_emp  \n",
      "0           2429.0    00:00:02:429     00:00:07:320  \n",
      "1           3600.0    00:00:03:600     00:00:08:970  \n",
      "2           5070.0    00:00:05:070     00:00:11:940  \n",
      "3           1770.0    00:00:01:770     00:00:15:990  \n",
      "4           8729.0    00:00:08:729     00:00:17:070  \n",
      "5           4620.0    00:00:04:620     00:00:24:780  \n",
      "6           3180.0    00:00:03:180     00:00:26:190  \n",
      "7           2460.0    00:00:02:460     00:00:30:060  \n",
      "8           3749.0    00:00:03:749     00:00:32:220  \n",
      "9           2879.0    00:00:02:879     00:00:34:080  \n",
      "10          7049.0    00:00:07:049     00:00:37:170  \n",
      "11          2430.0    00:00:02:430     00:00:39:360  \n",
      "12          8520.0    00:00:08:520     00:00:45:540  \n",
      "13          3899.0    00:00:03:899     00:00:47:370  \n",
      "14          2939.0    00:00:02:939     00:00:55:260  \n",
      "15          4590.0    00:00:04:590     00:00:58:500  \n",
      "16         11999.0    00:00:11:999     00:01:00:420  \n",
      "17         47040.0    00:00:47:040     00:01:03:990  \n",
      "18          3389.0    00:00:03:389     00:01:14:970  \n",
      "19          8100.0    00:00:08:100     00:02:00:990  \n",
      "20          7710.0    00:00:07:710     00:02:03:360  \n",
      "21          4349.0    00:00:04:349     00:02:10:440  \n",
      "22          9509.0    00:00:09:509     00:02:17:130  \n",
      "23          2880.0    00:00:02:880     00:02:20:910  \n",
      "24          2549.0    00:00:02:549     00:02:29:700  \n",
      "25          8069.0    00:00:08:069     00:02:31:650  \n",
      "26          6659.0    00:00:06:659     00:02:33:570  \n",
      "27          3000.0    00:00:03:000     00:02:41:010  \n",
      "28          3089.0    00:00:03:089     00:02:46:650  \n",
      "29          4799.0    00:00:04:799     00:02:48:630  \n",
      "30          6089.0    00:00:06:089     00:02:51:090  \n",
      "31          2740.0    00:00:02:740     00:02:55:290  \n",
      "32             NaN             NaN     00:03:03:330  \n",
      "33             NaN             NaN     00:03:08:760  \n",
      "                                         df_words_emp  row_number  \\\n",
      "0                  [да накопительного счета на карту]           0   \n",
      "1                                             [да да]           1   \n",
      "2                 [я его не помню Наталья может типа]           2   \n",
      "3                                           [Наталья]           3   \n",
      "4                                              [Илья]           4   \n",
      "5           [на карту премиальные карты не открывали]           5   \n",
      "6                            [да да да все правильно]           6   \n",
      "7                                       [да да да да]           7   \n",
      "8   [ну я могу перевести на карту которые не откры...           8   \n",
      "9                                               [угу]           9   \n",
      "10              [то есть у меня должна получиться да]          10   \n",
      "11        [он мне после про какой-то лимит постоянно]          11   \n",
      "12                                              [угу]          12   \n",
      "13                             [хорошо ладно спасибо]          13   \n",
      "14                              [нет угу до свидания]          14   \n",
      "\n",
      "    df_hum_sec_emp df_hum_dttm_emp df_start_sec_emp  \n",
      "0           8400.0    00:00:08:400     00:00:09:180  \n",
      "1           5519.0    00:00:05:519     00:00:16:830  \n",
      "2          12120.0    00:00:12:120     00:00:24:660  \n",
      "3          13620.0    00:00:13:620     00:00:29:160  \n",
      "4           6300.0    00:00:06:300     00:00:40:260  \n",
      "5           6359.0    00:00:06:359     00:00:53:190  \n",
      "6          12510.0    00:00:12:510     00:00:58:860  \n",
      "7          12029.0    00:00:12:029     00:01:04:530  \n",
      "8           4860.0    00:00:04:860     00:01:16:440  \n",
      "9          12899.0    00:00:12:899     00:01:27:450  \n",
      "10         14879.0    00:00:14:879     00:01:31:740  \n",
      "11          5039.0    00:00:05:039     00:01:44:040  \n",
      "12          3600.0    00:00:03:600     00:01:57:900  \n",
      "13          1750.0    00:00:01:750     00:02:02:250  \n",
      "14             NaN             NaN     00:02:05:100  \n",
      "                                         df_words_emp  row_number  \\\n",
      "0   [здравствуйте организация торговый дом москвор...           0   \n",
      "1   [подскажите пожалуйста вот у нас система бизне...           1   \n",
      "2   [вот будут заканчиваться снова декабря и там о...           2   \n",
      "3   [и раньше мы распечатали эти сертификаты ещё п...           3   \n",
      "4   [сейчас их не надо вести он нам не дает их печ...           4   \n",
      "5                                           [Наталья]           5   \n",
      "6   [ну да там есть кнопочка распечатать для предо...           6   \n",
      "7                                 [7 (720) 466-50-66]           7   \n",
      "8                       [о торговый дом москворецкий]           8   \n",
      "9                                             [37 57]           9   \n",
      "10                                     [логин сейчас]          10   \n",
      "11                                         [ну давай]          11   \n",
      "12                                   [94 22:30 39 55]          12   \n",
      "13                                              [угу]          13   \n",
      "14  [а сейчас у нас ну по по-старому ходим как бы ...          14   \n",
      "15                                              [ага]          15   \n",
      "16  [ага соответственно нам ничего не нужно вести ...          16   \n",
      "17  [ага это вот по этой системе потому что бизнес...          17   \n",
      "18  [а как мы узнаем что там они генерировать выпу...          18   \n",
      "19  [а уведомление появится как будто заходить угу...          19   \n",
      "20                                      [до свидания]          20   \n",
      "\n",
      "    df_hum_sec_emp df_hum_dttm_emp df_start_sec_emp  \n",
      "0           4020.0    00:00:04:020     00:00:04:050  \n",
      "1           8850.0    00:00:08:850     00:00:07:320  \n",
      "2          10649.0    00:00:10:649     00:00:15:570  \n",
      "3           6600.0    00:00:06:600     00:00:25:620  \n",
      "4           5519.0    00:00:05:519     00:00:31:560  \n",
      "5          10919.0    00:00:10:919     00:00:36:060  \n",
      "6          19170.0    00:00:19:170     00:00:46:380  \n",
      "7          11399.0    00:00:11:399     00:00:58:410  \n",
      "8           7979.0    00:00:07:979     00:01:09:120  \n",
      "9           4139.0    00:00:04:139     00:01:16:140  \n",
      "10          6779.0    00:00:06:779     00:01:19:560  \n",
      "11         11099.0    00:00:11:099     00:01:25:680  \n",
      "12         57959.0    00:00:57:959     00:01:32:340  \n",
      "13          9150.0    00:00:09:150     00:01:42:420  \n",
      "14          3120.0    00:00:03:120     00:02:39:660  \n",
      "15          7649.0    00:00:07:649     00:02:47:790  \n",
      "16          6300.0    00:00:06:300     00:02:50:040  \n",
      "17          7739.0    00:00:07:739     00:02:57:000  \n",
      "18          7439.0    00:00:07:439     00:03:02:670  \n",
      "19           970.0    00:00:00:970     00:03:09:690  \n",
      "20             NaN             NaN     00:03:16:500  \n",
      "\n",
      "Конец отработки функции: 2021-12-03 07:53:12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Кол-во файлов в папке: 1\n",
      "\n",
      "Начало анализа: 2021-12-03 07:53:12\n",
      "Конец анализа:  2021-12-03 07:53:12\n",
      "Начало загрузки: 2021-12-03 07:53:12, файл: 1. Final_phrases.csv\n",
      "Считано записей: 241\n",
      "Without an HDFS connection, certain functionality may be disabled\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import sched, time, datetime\n",
    "s = sched.scheduler(time.time, time.sleep)\n",
    "from impala.dbapi import connect\n",
    "\n",
    "# c какого дня скрипт начнёт отрабатывать \n",
    "a = datetime.datetime(2021, 12, 3, 7, 53, 0) \n",
    "\n",
    "# mktime - возвращает кол-во секунд, прошедшее с момент 1 января 1970 (эпоха Windows)\n",
    "time_to_run = time.mktime(time.strptime(str(a), '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Цикл запуска обновления со следущего дня\n",
    "while True:    \n",
    "    \n",
    "    # Преобразование даты в формат пригодный для scheduler.enterabs\n",
    "    time_to_run = time.mktime(time.strptime(str(a), '%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    # time_to_run - время, 1 - приоритет, our_func_action - действие\n",
    "    s.enterabs(time_to_run, 1, our_func_action)\n",
    "    \n",
    "    s.run()         \n",
    "    \n",
    "    # Следующее время запуска\n",
    "    a += datetime.timedelta(days=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Куда всё будем загружать в Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Папка, из которой мы загружаем файлы\n",
    "folder = '/work/ML_FINAL'\n",
    "\n",
    "# База, в которую грузим (в т.ч. временную таблицу)\n",
    "database = 'sbx_dml'\n",
    "\n",
    "# Название временной таблицы\n",
    "temp_table = 'ml_call_phrases'\n",
    "\n",
    "# Название итоговой таблицы\n",
    "table = 'call_phrases_ml'\n",
    "\n",
    "# Разделитель в файлах\n",
    "sep = ';'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполняем первым шагом запуск всех необходимых функций и модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket cache: FILE:/tmp/krb5cc\n",
      "Default principal: gpbu23013@INT.GAZPROMBANK.RU\n",
      "\n",
      "Valid starting       Expires              Service principal\n",
      "12/03/2021 07:45:49  12/03/2021 17:45:49  krbtgt/INT.GAZPROMBANK.RU@INT.GAZPROMBANK.RU\n",
      "\trenew until 12/10/2021 07:45:49\n",
      "12/03/2021 07:46:32  12/03/2021 17:45:49  impala/hdp-p3pml.int.gazprombank.ru@INT.GAZPROMBANK.RU\n",
      "\trenew until 12/10/2021 07:45:49\n",
      "12/03/2021 07:46:38  12/03/2021 17:45:49  HTTP/hdp-p3pml.int.gazprombank.ru@INT.GAZPROMBANK.RU\n",
      "\trenew until 12/10/2021 07:45:49\n",
      "Ticket cache: FILE:/tmp/krb5cc\n",
      "Default principal: gpbu23013@INT.GAZPROMBANK.RU\n",
      "\n",
      "Valid starting       Expires              Service principal\n",
      "12/03/2021 07:52:54  12/03/2021 17:52:54  krbtgt/INT.GAZPROMBANK.RU@INT.GAZPROMBANK.RU\n",
      "\trenew until 12/10/2021 07:52:54\n"
     ]
    }
   ],
   "source": [
    "''' ---------------------------------------------- ДЕЛАЕМ ПЕРЕЛОГИН --------------------------------------- '''\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import os\n",
    "from impala.dbapi import connect\n",
    "import re\n",
    "\n",
    "# Получение нового тикета доступа\n",
    "login = 'gpbu23013'\n",
    "password = '19981828Eugene'\n",
    "!klist\n",
    "\n",
    "os.system('echo ' + password + ' | kinit ' + login)\n",
    "!klist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' -------------------------------- НЕОБХОДИМЫЕ ФУНКЦИИ И МОДУЛИ --------------------------------------------- '''\n",
    "\n",
    "# функция для перевода миллисекунд в формат 00:00:00:00\n",
    "def convert(mlseconds):\n",
    "    if (mlseconds // 3600000) == 0:\n",
    "        hour = 0\n",
    "    else:\n",
    "        hour = (mlseconds // 3600000)\n",
    "    mlseconds %= 3600000\n",
    "\n",
    "    \n",
    "    if (mlseconds // 60000) == 0:\n",
    "        minutes = 0\n",
    "    else:\n",
    "        minutes = (mlseconds // 60000)\n",
    "    mlseconds %= 60000\n",
    "\n",
    "    if (mlseconds // 1000) == 0:\n",
    "        seconds = 0\n",
    "    else:\n",
    "        seconds = (mlseconds // 1000)\n",
    "\n",
    "    if (mlseconds % 1000) != 0:\n",
    "        miliseconds = (mlseconds % 1000)\n",
    "    else:\n",
    "        miliseconds = 0\n",
    "        \n",
    "\n",
    "    miliseconds = round(miliseconds, 3)\n",
    "    \n",
    "    return \"%02d:%02d:%02d:%03d\" % (hour, minutes, seconds, miliseconds)\n",
    "\n",
    "\n",
    "# циклы для перевода\n",
    "def write_array(a):\n",
    "    x = []\n",
    "    for i in range(len(a)):\n",
    "        x.append(convert(a[i]))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "def obrabotka(df):\n",
    "    \n",
    "    \n",
    "    # создаём папочку для хранения построенных диаграмм\n",
    "    dir = '/work/ML_PHRASES/'\n",
    "     \n",
    "    # если её нет - создаём    \n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)    \n",
    "\n",
    "    # следующие массивы понадобятся нам для подсчёта ошибок\n",
    "    errors = []\n",
    "    goods = []\n",
    "    dfs_all = []\n",
    "        \n",
    "        # создадим цикл для поочерёдной обработки каждой строки фрейма данных\n",
    "    for i in range(len(df['callid'])):\n",
    "        \n",
    "        try:\n",
    "        \n",
    "\n",
    "            #print(len('{}'.format(df['result'][i])))\n",
    "\n",
    "            # наш строковый xml (locals()[\"group\" + str(i)]  - возможность переименовывать переменную в цикле)\n",
    "            locals()[\"xmlData_employee\" + str(i)] = \"'''{0}'''\".format(str(df['result_1'][i]))\n",
    "            locals()[\"xmlData_client\" + str(i)] = \"'''{0}'''\".format(str(df['result_0'][i]))\n",
    "\n",
    "\n",
    "             # c помощью регулярных выражений ищем значения в кавычках после опр. слов\n",
    "             # для слов\n",
    "            locals()[\"WordText_employee\" + str(i)] = re.findall(r'Word Text=\"(.*?)\"', str(locals()[\"xmlData_employee\" + str(i)]))\n",
    "            locals()[\"WordText_client\" + str(i)] = re.findall(r'Word Text=\"(.*?)\"', str(locals()[\"xmlData_client\" + str(i)]))\n",
    "            #print('\\n' + str(locals()[\"WordText_employee\" + str(i)]) + '\\n\\n')\n",
    "            #print('\\n' + str(locals()[\"WordText_client\" + str(i)]) + '\\n\\n')\n",
    "\n",
    "             # для секунд старта\n",
    "            locals()[\"StartMst_employee\" + str(i)] = re.findall(r'StartMs=\"(.*?)\"', str(locals()[\"xmlData_employee\" + str(i)]))\n",
    "            locals()[\"StartMst_client\" + str(i)] = re.findall(r'StartMs=\"(.*?)\"', str(locals()[\"xmlData_client\" + str(i)]))\n",
    "\n",
    "             # переводим в вещ. тип\n",
    "            locals()[\"StartMst_employee\" + str(i)] = [float(x) for x in locals()[\"StartMst_employee\" + str(i)]]\n",
    "            locals()[\"StartMst_client\" + str(i)] = [float(x) for x in locals()[\"StartMst_client\" + str(i)]]\n",
    "            #print(locals()[\"StartMst_employee\" + str(i)])\n",
    "\n",
    "\n",
    "             # для секунд окончания\n",
    "            locals()[\"EndMs_employee\" + str(i)] = re.findall(r'EndMs=\"(.*?)\"', str(locals()[\"xmlData_employee\" + str(i)]))\n",
    "            locals()[\"EndMs_employee\" + str(i)] = [float(x) for x in locals()[\"EndMs_employee\" + str(i)]]\n",
    "\n",
    "            locals()[\"EndMs_client\" + str(i)] = re.findall(r'EndMs=\"(.*?)\"', str(locals()[\"xmlData_client\" + str(i)]))\n",
    "            locals()[\"EndMs_client\" + str(i)] = [float(x) for x in locals()[\"EndMs_client\" + str(i)]]\n",
    "\n",
    "            # смотри разницу между началом и концом разговора ДЛЯ СОТРУДНИКА\n",
    "            locals()[\"hum_dttm_employee\" + str(i)] = []\n",
    "\n",
    "            for j in range(len(locals()[\"StartMst_employee\" + str(i)])):\n",
    "                 locals()[\"hum_dttm_employee\" + str(i)].append(locals()[\"EndMs_employee\" + str(i)][j] - locals()[\"StartMst_employee\" + str(i)][j])\n",
    "\n",
    "\n",
    "            # смотри разницу между началом и концом разговора ДЛЯ КЛИЕНТА\n",
    "            locals()[\"hum_dttm_client\" + str(i)] = []\n",
    "\n",
    "            for j in range(len(locals()[\"StartMst_client\" + str(i)])):\n",
    "                 locals()[\"hum_dttm_client\" + str(i)].append(locals()[\"EndMs_client\" + str(i)][j] - locals()[\"StartMst_client\" + str(i)][j])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            locals()[\"hum_dttm_emp\" + str(i)] = write_array(locals()[\"hum_dttm_employee\" + str(i)])\n",
    "            locals()[\"StartMst_emp\" + str(i)] = write_array(locals()[\"StartMst_employee\" + str(i)])\n",
    "            locals()[\"EndMs_empl\" + str(i)] = write_array(locals()[\"EndMs_employee\" + str(i)])\n",
    "\n",
    "            locals()[\"hum_dttm_cl\" + str(i)] = write_array(locals()[\"hum_dttm_client\" + str(i)])\n",
    "            locals()[\"StartMst_cl\" + str(i)] = write_array(locals()[\"StartMst_client\" + str(i)])\n",
    "            locals()[\"EndMs_cl\" + str(i)] = write_array(locals()[\"EndMs_client\" + str(i)])\n",
    "\n",
    "            #print(('WordText_employee: ' + str(locals()[\"WordText_employee\" + str(i)]) + '  len:  ' + str(len((locals()[\"WordText_employee\" + str(i)]))) + '\\n'))\n",
    "            #print(('hum_dttm_emp: ' + str(locals()[\"hum_dttm_emp\" + str(i)]) + '  len:  ' + str(len((locals()[\"hum_dttm_emp\" + str(i)]))) + '\\n'))\n",
    "            #print(('StartMst_emp: ' + str(locals()[\"StartMst_emp\" + str(i)]) + '  len:  ' + str(len((locals()[\"StartMst_emp\" + str(i)]))) + '\\n'))\n",
    "            #print(('EndMs_empl: ' + str(locals()[\"EndMs_empl\" + str(i)]) + '  len:  ' + str(len((locals()[\"EndMs_empl\" + str(i)]))) + '\\n'))\n",
    "            #print(('StartMst_employee: ' + str(locals()[\"StartMst_employee\" + str(i)]) + '  len:  ' + str(len((locals()[\"StartMst_employee\" + str(i)]))) + '\\n'))\n",
    "\n",
    "\n",
    "            # собираем всё в фрейм данных ДЛЯ СОТРУДНИКА\n",
    "            locals()[\"df_employee\" + str(i)] = pd.DataFrame({'words': locals()[\"WordText_employee\" + str(i)],\n",
    "                                                             'hum_dttm': locals()[\"hum_dttm_emp\" + str(i)],\n",
    "                                                             'start_dttm' : locals()[\"StartMst_emp\" + str(i)],\n",
    "                                                             'finish_dttm': locals()[\"EndMs_empl\" + str(i)],\n",
    "                                                             'start_sec' : locals()[\"StartMst_employee\" + str(i)],\n",
    "                                                             'finish_sec': locals()[\"EndMs_employee\" + str(i)]\n",
    "                                                            })\n",
    "            #print(locals()[\"df_employee\" + str(i)])\n",
    "            \n",
    "\n",
    "            # искусственно добавляем ещё строку False (чтобы считалась последняя фраза)\n",
    "            locals()[\"df_last_loc_emp\" + str(i)] = pd.DataFrame({'words': '', \n",
    "                                                             'hum_dttm': '', #((locals()[\"df_employee\" + str(i)]['hum_dttm']).max() + 10), \n",
    "                                                             'start_dttm': '', #((locals()[\"df_employee\" + str(i)]['start_dttm']).max() + 10), \n",
    "                                                             'finish_dttm': '', #((locals()[\"df_employee\" + str(i)]['finish_dttm']).max() + 10), \n",
    "                                                             'start_sec': (max(locals()[\"StartMst_employee\" + str(i)]) + 10), \n",
    "                                                             'finish_sec': (max(locals()[\"EndMs_employee\" + str(i)]) + 10)   \n",
    "                                                              }, index = [(len(locals()[\"StartMst_employee\" + str(i)]))]\n",
    "                                                             )\n",
    "\n",
    "            #print(locals()[\"df_last_loc\" + str(i)])\n",
    "            locals()[\"df_employee\" + str(i)] = locals()[\"df_employee\" + str(i)].append(locals()[\"df_last_loc_emp\" + str(i)])\n",
    "\n",
    "\n",
    "            # собираем всё в фрейм данных ДЛЯ КЛИЕНТА\n",
    "            locals()[\"df_client\" + str(i)] = pd.DataFrame({'words': locals()[\"WordText_client\" + str(i)],\n",
    "                                                             'hum_dttm': locals()[\"hum_dttm_cl\" + str(i)],\n",
    "                                                             'start_dttm' : locals()[\"StartMst_cl\" + str(i)],\n",
    "                                                             'finish_dttm': locals()[\"EndMs_cl\" + str(i)],\n",
    "                                                             'start_sec' : locals()[\"StartMst_client\" + str(i)],\n",
    "                                                             'finish_sec': locals()[\"EndMs_client\" + str(i)]\n",
    "                                                            })\n",
    "\n",
    "            # искусственно добавляем ещё строку False (чтобы считалась последняя фраза)\n",
    "            locals()[\"df_last_loc_cl\" + str(i)] = pd.DataFrame({'words': '', \n",
    "                                                             'hum_dttm': '', #((locals()[\"df_employee\" + str(i)]['hum_dttm']).max() + 10), \n",
    "                                                             'start_dttm': '', #((locals()[\"df_employee\" + str(i)]['start_dttm']).max() + 10), \n",
    "                                                             'finish_dttm': '', #((locals()[\"df_employee\" + str(i)]['finish_dttm']).max() + 10), \n",
    "                                                             'start_sec': (max(locals()[\"StartMst_client\" + str(i)]) + 10), \n",
    "                                                             'finish_sec': (max(locals()[\"EndMs_client\" + str(i)]) + 10)   \n",
    "                                                              }, index = [(len(locals()[\"StartMst_client\" + str(i)]))]\n",
    "                                                             )\n",
    "\n",
    "            #print(locals()[\"df_last_loc\" + str(i)])\n",
    "            locals()[\"df_client\" + str(i)] = locals()[\"df_client\" + str(i)].append(locals()[\"df_last_loc_cl\" + str(i)])\n",
    "\n",
    "            #print('\\033[1m' + '\\nДлина DataFrame: ' + str(len(locals()[\"df_client\" + str(i)]['words'])) + '\\033[0m')\n",
    "            #print('\\033[1m' + '\\nДлина DataFrame: ' + str(len(locals()[\"df_employee\" + str(i)]['words'])) + '\\033[0m')\n",
    "            #print('\\n\\n')\n",
    "            #print(locals()[\"df_itog\" + str(i)])\n",
    "            #print('\\nПЕРЕХОД\\n')\n",
    "\n",
    "            # функция lag для смещения строки вниз\n",
    "            locals()[\"df_employee\" + str(i)]['lead_finish_sec'] = locals()[\"df_employee\" + str(i)]['finish_sec'].shift(1)\n",
    "            locals()[\"df_employee\" + str(i)]['lead_start_sec'] = locals()[\"df_employee\" + str(i)]['start_sec'].shift(1)\n",
    "            locals()[\"df_employee\" + str(i)]['lead_finish_sec'] = locals()[\"df_employee\" + str(i)]['lead_finish_sec'].fillna(0)\n",
    "            locals()[\"df_client\" + str(i)]['lead_finish_sec'] = locals()[\"df_client\" + str(i)]['finish_sec'].shift(1)\n",
    "            locals()[\"df_client\" + str(i)]['lead_start_sec'] = locals()[\"df_client\" + str(i)]['start_sec'].shift(1)\n",
    "            locals()[\"df_client\" + str(i)]['lead_finish_sec'] = locals()[\"df_client\" + str(i)]['lead_finish_sec'].fillna(0)\n",
    "\n",
    "            # округляем\n",
    "            locals()[\"df_employee\" + str(i)]['lead_finish_sec'] = round(locals()[\"df_employee\" + str(i)]['lead_finish_sec'], -1)\n",
    "            locals()[\"df_employee\" + str(i)]['lead_start_sec'] = round(locals()[\"df_employee\" + str(i)]['lead_start_sec'], -1)\n",
    "            locals()[\"df_client\" + str(i)]['lead_finish_sec'] = round(locals()[\"df_client\" + str(i)]['lead_finish_sec'], -1)\n",
    "            locals()[\"df_client\" + str(i)]['lead_start_sec'] = round(locals()[\"df_client\" + str(i)]['lead_start_sec'], -1)\n",
    "\n",
    "            # CРАВНИВАЕМ\n",
    "            locals()[\"df_employee\" + str(i)]['flg'] = locals()[\"df_employee\" + str(i)]['lead_finish_sec'] == locals()[\"df_employee\" + str(i)]['start_sec']\n",
    "            locals()[\"df_client\" + str(i)]['flg'] = locals()[\"df_client\" + str(i)]['lead_finish_sec'] == locals()[\"df_client\" + str(i)]['start_sec']\n",
    "\n",
    "\n",
    "            # отбираем нужные нам поля\n",
    "            locals()[\"df_employee\" + str(i)] = locals()[\"df_employee\" + str(i)][['words', 'hum_dttm', 'start_sec', 'finish_sec', 'lead_finish_sec', 'flg']]\n",
    "            locals()[\"df_employee\" + str(i)] = locals()[\"df_employee\" + str(i)].sort_values(by = 'start_sec', kind='mergesort')\n",
    "            locals()[\"df_client\" + str(i)] = locals()[\"df_client\" + str(i)][['words', 'hum_dttm', 'start_sec', 'finish_sec', 'lead_finish_sec', 'flg']]\n",
    "            locals()[\"df_client\" + str(i)] = locals()[\"df_client\" + str(i)].sort_values(by = 'start_sec', kind='mergesort')\n",
    "\n",
    "            # вытягиваем индексы, чтобы разметить границы\n",
    "            locals()[\"index_true_emp\" + str(i)] = locals()[\"df_employee\" + str(i)]['flg'][locals()[\"df_employee\" + str(i)]['flg'] == True].index.tolist()\n",
    "            locals()[\"index_false_emp\" + str(i)] = locals()[\"df_employee\" + str(i)]['flg'][locals()[\"df_employee\" + str(i)]['flg'] == False].index.tolist()\n",
    "            locals()[\"index_true_cl\" + str(i)] = locals()[\"df_client\" + str(i)]['flg'][locals()[\"df_client\" + str(i)]['flg'] == True].index.tolist()\n",
    "            locals()[\"index_false_cl\" + str(i)] = locals()[\"df_client\" + str(i)]['flg'][locals()[\"df_client\" + str(i)]['flg'] == False].index.tolist()\n",
    "\n",
    "\n",
    "            #print('\\033[1m' + '\\n\\nСформировали DataFrame № {}: \\n'.format(i) + '\\033[0m')\n",
    "            #print('\\033[1m' + '\\nСотрудник: \\n\\n' + '\\033[0m')\n",
    "            #print(locals()[\"df_employee\" + str(i)])\n",
    "            #print('\\033[1m' + '\\nДлина DataFrame: ' + str(len(locals()[\"df_employee\" + str(i)]['words'])) + '\\033[0m')        \n",
    "            #print('\\033[1m' + '\\nКлиент: \\n\\n' + '\\033[0m')\n",
    "            #print(locals()[\"df_client\" + str(i)])\n",
    "            #print('\\033[1m' + '\\nДлина DataFrame: ' + str(len(locals()[\"df_client\" + str(i)]['words'])) + '\\033[0m')        \n",
    "            #print('\\n\\n')\n",
    "\n",
    "\n",
    "            # СЛОЖНЫЙ ЦИКЛ (чтобы собрать слова в фразы)\n",
    "\n",
    "\n",
    "            # СОТРУДНИК\n",
    "            locals()[\"words_emp\" + str(i)] = [] # формируем массив из массивов\n",
    "            locals()[\"hum_dttm_emp\" + str(i)] = []\n",
    "            locals()[\"start_sec_emp\" + str(i)] = []\n",
    "\n",
    "            for m in range(len(locals()[\"index_false_emp\" + str(i)]) - 1):\n",
    "\n",
    "                (locals()[\"x_emp\" + str(i)]) = [] # формируем массив из слов\n",
    "\n",
    "                (locals()[\"words_emp\" + str(i)]).append(locals()[\"x_emp\" + str(i)]) # массивы x кладём в y\n",
    "\n",
    "                for k in range(locals()[\"index_false_emp\" + str(i)][m], locals()[\"index_false_emp\" + str(i)][m+1]):\n",
    "                    #print(range(index_false[j], index_false[j+1]))\n",
    "\n",
    "                    (locals()[\"x_emp\" + str(i)]).append(locals()[\"df_employee\" + str(i)]['words'][k])\n",
    "                    #print(str(df['finish_sec'][index_false[j+1]]) + ' ' + str(df['start_sec'][index_false[j]]))\n",
    "                    (locals()[\"hum_dttm_emp\" + str(i)]).append( str(locals()[\"df_employee\" + str(i)]['finish_sec'][locals()[\"index_false_emp\" + str(i)][m+1]] - (locals()[\"df_employee\" + str(i)])['start_sec'][locals()[\"index_false_emp\" + str(i)][m]]))\n",
    "                    locals()[\"start_sec_emp\" + str(i)].append(str(locals()[\"df_employee\" + str(i)]['start_sec'][locals()[\"index_false_emp\" + str(i)][m]]))\n",
    "\n",
    "\n",
    "            # КЛИЕНТ\n",
    "            locals()[\"words_cl\" + str(i)] = [] # формируем массив из массивов\n",
    "            locals()[\"hum_dttm_cl\" + str(i)] = []\n",
    "            locals()[\"start_sec_cl\" + str(i)] = []\n",
    "\n",
    "            for m in range(len(locals()[\"index_false_cl\" + str(i)]) - 1):\n",
    "\n",
    "                (locals()[\"x_cl\" + str(i)]) = [] # формируем массив из слов\n",
    "\n",
    "                (locals()[\"words_cl\" + str(i)]).append(locals()[\"x_cl\" + str(i)]) # массивы x кладём в y\n",
    "\n",
    "                for k in range(locals()[\"index_false_cl\" + str(i)][m], locals()[\"index_false_cl\" + str(i)][m+1]):\n",
    "                    #print(range(index_false[j], index_false[j+1]))\n",
    "\n",
    "                    (locals()[\"x_cl\" + str(i)]).append(locals()[\"df_client\" + str(i)]['words'][k])\n",
    "                    #print(str(df['finish_sec'][index_false[j+1]]) + ' ' + str(df['start_sec'][index_false[j]]))\n",
    "                    (locals()[\"hum_dttm_cl\" + str(i)]).append( str(locals()[\"df_client\" + str(i)]['finish_sec'][locals()[\"index_false_cl\" + str(i)][m+1]] - (locals()[\"df_client\" + str(i)])['start_sec'][locals()[\"index_false_cl\" + str(i)][m]]))\n",
    "                    locals()[\"start_sec_cl\" + str(i)].append(str(locals()[\"df_client\" + str(i)]['start_sec'][locals()[\"index_false_cl\" + str(i)][m]]))\n",
    "\n",
    "\n",
    "             # сливаем слова в фразы\n",
    "            locals()[\"words_new_emp\" + str(i)] = [[' '.join(s)] for s in (locals()[\"words_emp\" + str(i)])]\n",
    "            locals()[\"words_new_cl\" + str(i)] = [[' '.join(s)] for s in (locals()[\"words_cl\" + str(i)])]\n",
    "            \n",
    "\n",
    "\n",
    "             # удаляем дубликаты из списка\n",
    "            (locals()[\"start_sec_emp\" + str(i)]) = list(OrderedDict.fromkeys((locals()[\"start_sec_emp\" + str(i)])))\n",
    "            (locals()[\"start_sec_emp\" + str(i)]) = [float(x) for x in (locals()[\"start_sec_emp\" + str(i)])]\n",
    "            (locals()[\"start_sec_emp\" + str(i)]) = write_array((locals()[\"start_sec_emp\" + str(i)]))\n",
    "\n",
    "            (locals()[\"start_sec_cl\" + str(i)]) = list(OrderedDict.fromkeys((locals()[\"start_sec_cl\" + str(i)])))\n",
    "            (locals()[\"start_sec_cl\" + str(i)]) = [float(x) for x in (locals()[\"start_sec_cl\" + str(i)])]\n",
    "            (locals()[\"start_sec_cl\" + str(i)]) = write_array((locals()[\"start_sec_cl\" + str(i)]))       \n",
    "\n",
    "            # удаляем дубликаты из списка\n",
    "            (locals()[\"hum_sec_emp\" + str(i)]) = list(OrderedDict.fromkeys((locals()[\"hum_dttm_emp\" + str(i)])))\n",
    "            (locals()[\"hum_sec_emp\" + str(i)]) = [float(x) for x in (locals()[\"hum_sec_emp\" + str(i)])]\n",
    "            (locals()[\"hum_dttm_emp\" + str(i)]) = write_array((locals()[\"hum_sec_emp\" + str(i)]))     \n",
    "            (locals()[\"hum_sec_cl\" + str(i)]) = list(OrderedDict.fromkeys((locals()[\"hum_dttm_cl\" + str(i)])))\n",
    "            (locals()[\"hum_sec_cl\" + str(i)]) = [float(x) for x in (locals()[\"hum_sec_cl\" + str(i)])]\n",
    "            (locals()[\"hum_dttm_cl\" + str(i)]) = write_array((locals()[\"hum_sec_cl\" + str(i)]))       \n",
    "\n",
    "\n",
    "            #print(str(locals()[\"start_sec\" + str(i)]) + ' длина start_sec: ' + str(len(locals()[\"start_sec\" + str(i)])) + '\\n')\n",
    "            #print(str(locals()[\"words_new\" + str(i)]) + ' длина words_new: ' + str(len(locals()[\"words_new\" + str(i)])) + '\\n')\n",
    "            #print(str(locals()[\"hum_dttm\" + str(i)]) + ' длина hum_dttm: ' + str(len(locals()[\"hum_dttm\" + str(i)])) + '\\n')\n",
    "            #print(str(locals()[\"hum_sec\" + str(i)]) + ' длина hum_sec: ' + str(len(locals()[\"hum_sec\" + str(i)])) + '\\n')\n",
    "\n",
    "\n",
    "             # ПОСКОЛЬКУ ИНОГДА ФРАЗЫ ГЕНЕРЯТСЯ С ОШИБКАМИ ИЗ-ЗА ОШИБОК РАСПОЗНОВАНИЯ СИСТЕМОЙ РЕЧИ\n",
    "             # БУДЕМ ГЕНЕРИТЬ ОБЩИЙ ФРЕЙМ ИЗ НЕСКОЛЬКИХ МАЛЕНЬКИХ\n",
    "\n",
    "            \n",
    "            (locals()[\"df_words_emp\" + str(i)]) = pd.DataFrame({'df_words_emp': (locals()[\"words_new_emp\" + str(i)])})\n",
    "            (locals()[\"df_words_emp\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_words_emp\" + str(i)])))\n",
    "\n",
    "            (locals()[\"df_hum_sec_emp\" + str(i)]) = pd.DataFrame({'df_hum_sec_emp': (locals()[\"hum_sec_emp\" + str(i)])})\n",
    "            (locals()[\"df_hum_sec_emp\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_hum_sec_emp\" + str(i)])))        \n",
    "\n",
    "            (locals()[\"df_hum_dttm_emp\" + str(i)]) = pd.DataFrame({'df_hum_dttm_emp': (locals()[\"hum_dttm_emp\" + str(i)])})\n",
    "            (locals()[\"df_hum_dttm_emp\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_hum_dttm_emp\" + str(i)])))\n",
    "\n",
    "            (locals()[\"df_start_sec_emp\" + str(i)]) = pd.DataFrame({'df_start_sec_emp': (locals()[\"start_sec_emp\" + str(i)])})\n",
    "            (locals()[\"df_start_sec_emp\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_start_sec_emp\" + str(i)])))\n",
    "\n",
    "\n",
    "            (locals()[\"df_words_cl\" + str(i)]) = pd.DataFrame({'df_words_emp': (locals()[\"words_new_cl\" + str(i)])})\n",
    "            (locals()[\"df_words_cl\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_words_cl\" + str(i)])))\n",
    "\n",
    "            (locals()[\"df_hum_sec_cl\" + str(i)]) = pd.DataFrame({'df_hum_sec_emp': (locals()[\"hum_sec_cl\" + str(i)])})\n",
    "            (locals()[\"df_hum_sec_cl\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_hum_sec_cl\" + str(i)])))        \n",
    "\n",
    "            (locals()[\"df_hum_dttm_cl\" + str(i)]) = pd.DataFrame({'df_hum_dttm_emp': (locals()[\"hum_dttm_cl\" + str(i)])})\n",
    "            (locals()[\"df_hum_dttm_cl\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_hum_dttm_cl\" + str(i)])))\n",
    "\n",
    "            (locals()[\"df_start_sec_cl\" + str(i)]) = pd.DataFrame({'df_start_sec_emp': (locals()[\"start_sec_cl\" + str(i)])})\n",
    "            (locals()[\"df_start_sec_cl\" + str(i)])['row_number'] = np.arange(len((locals()[\"df_start_sec_cl\" + str(i)])))\n",
    "\n",
    "            \n",
    "\n",
    "            locals()[\"df_client\" + str(i)] = (locals()[\"df_words_cl\" + str(i)]).merge((locals()[\"df_hum_sec_cl\" + str(i)]), how = 'left', on = 'row_number').merge((locals()[\"df_hum_dttm_cl\" + str(i)]), how = 'left', on = 'row_number').merge((locals()[\"df_start_sec_cl\" + str(i)]), how = 'left', on = 'row_number')\n",
    "            locals()[\"df_employee\" + str(i)] = (locals()[\"df_words_emp\" + str(i)]).merge((locals()[\"df_hum_sec_emp\" + str(i)]), how = 'left', on = 'row_number').merge((locals()[\"df_hum_dttm_emp\" + str(i)]), how = 'left', on = 'row_number').merge((locals()[\"df_start_sec_emp\" + str(i)]), how = 'left', on = 'row_number')\n",
    "\n",
    "            #print(locals()[\"df_client\" + str(i)])\n",
    "            # проставляем флаги \n",
    "            locals()[\"df_employee\" + str(i)]['who'] = '1'\n",
    "            locals()[\"df_client\" + str(i)]['who'] = '0'\n",
    "\n",
    "            locals()[\"df_employee\" + str(i)].columns = ['df_words', 'row_number', 'df_hum_sec', 'df_hum_dttm', 'df_start_sec', 'who']\n",
    "            locals()[\"df_client\" + str(i)].columns = ['df_words', 'row_number', 'df_hum_sec', 'df_hum_dttm', 'df_start_sec', 'who']\n",
    "\n",
    "\n",
    "            # Предварительно почистим csv-файлы в директории, потому что заменить их не получится\n",
    "            if os.path.isfile('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 1)):\n",
    "                os.remove('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 1))       \n",
    "            elif os.path.isfile('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 0)):\n",
    "                os.remove('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 0))\n",
    "\n",
    "            # переместим наш фрейм в csv-формат\n",
    "            locals()[\"df_employee\" + str(i)].to_csv('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 1), encoding = 'utf-8', index = False, sep = ';')\n",
    "            locals()[\"df_client\" + str(i)].to_csv('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 0), encoding = 'utf-8', index = False, sep = ';')\n",
    "\n",
    "            locals()[\"df_employee\" + str(i)] = pd.read_csv('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 1), encoding = 'utf-8', sep = ';')\n",
    "            locals()[\"df_client\" + str(i)] = pd.read_csv('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 0), encoding = 'utf-8', sep = ';')\n",
    "\n",
    "            # UNION датафреймов\n",
    "            locals()[\"df_itog\" + str(i)] = pd.concat([locals()[\"df_client\" + str(i)],  locals()[\"df_employee\" + str(i)]]).drop_duplicates().reset_index()\n",
    "            locals()[\"df_itog\" + str(i)] = locals()[\"df_itog\" + str(i)].sort_values(by = 'df_start_sec', kind = 'mergesort')\n",
    "\n",
    "            # снова отчищаем, чтобы не занимать место в пространстве\n",
    "            os.remove('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 1))\n",
    "            os.remove('/work/ML_PHRASES/DataFrame от {0}-{1}.csv'.format(i, 0))\n",
    "\n",
    "            # формируем итоговый фрейм с id звонка и датой     \n",
    "            locals()[\"df_last\" + str(i)]  = df[['insertutcdate', 'callid']][i:i+1]\n",
    "\n",
    "            # CROSS JOIN (для чего изначально сгенерим нулевые ключи)\n",
    "            locals()[\"df_last\" + str(i)]['key'] = 0\n",
    "            locals()[\"df_itog\" + str(i)]['key'] = 0\n",
    "            locals()[\"df\" + str(i)] = locals()[\"df_last\" + str(i)].merge(locals()[\"df_itog\" + str(i)], on = 'key', how = 'inner')\n",
    "\n",
    "            #print('\\033[1m' + '\\n\\n Получили: \\n' + '\\033[0m')\n",
    "            locals()[\"df\" + str(i)] = locals()[\"df\" + str(i)][['insertutcdate', 'callid', 'df_words', 'who', 'df_start_sec', 'df_hum_dttm', 'df_hum_sec']]\n",
    "\n",
    "            # переименовываем колонки\n",
    "            '''create_dt\tДата загрузки фразы в БД\n",
    "                call_id\tID звонка\n",
    "                phrase\tФраза\n",
    "                flg_who\tФлаг исполнителя разговора\n",
    "                who\tКто говорил\n",
    "                start_dttm\tВремя начала фразы\n",
    "                dlitelnost_phrase_sec\tДлительность фразы в секунда\n",
    "                dlitelnost_phrase\tДлительность фразы в формате 00:00:00 \n",
    "            '''\n",
    "\n",
    "            locals()[\"df\" + str(i)].columns = ['create_dt', 'call_id', 'phrase', 'who', 'start_dttm', 'dlitelnost_phrase_sec', 'dlitelnost_phrase']\n",
    "\n",
    "            # вытягиваем именно дату\n",
    "            locals()[\"df\" + str(i)]['create_dt'] = str(locals()[\"df\" + str(i)]['create_dt'])[:18]\n",
    "            \n",
    "            for s in range(len(locals()[\"df\" + str(i)]['create_dt'])):\n",
    "                locals()[\"df\" + str(i)]['create_dt'][s] = str(locals()[\"df\" + str(i)]['create_dt'][s]).replace('0    ', '')\n",
    "\n",
    "            # удаляем лишние символы в фразах\n",
    "            for p in range(len(locals()[\"df\" + str(i)]['phrase'])):\n",
    "\n",
    "                #locals()[\"df\" + str(i)]['phrase'][p] = '{0}'.format((locals()[\"df\" + str(i)]['phrase'][p]))\n",
    "                locals()[\"df\" + str(i)]['phrase'][p] = str(locals()[\"df\" + str(i)]['phrase'][p]).replace(\"[\", '')\n",
    "                locals()[\"df\" + str(i)]['phrase'][p] = str(locals()[\"df\" + str(i)]['phrase'][p]).replace(\"]\", '')\n",
    "                locals()[\"df\" + str(i)]['phrase'][p] = str(locals()[\"df\" + str(i)]['phrase'][p]).replace(\"'\", '')\n",
    "                locals()[\"df\" + str(i)]['phrase'][p] = str(locals()[\"df\" + str(i)]['phrase'][p]).replace(\"'\", '')\n",
    "\n",
    "\n",
    "            # Предварительно почистим csv-файлы в директории, потому что заменить их не получится\n",
    "            #if os.path.isfile('/work/ML_PHRASES/DataFrame от {0}.csv'.format(locals()[\"df\" + str(i)]['call_id'].unique())):\n",
    "                #os.remove('/work/ML_PHRASES/DataFrame от {0}.csv'.format(locals()[\"df\" + str(i)]['call_id'].unique()))       \n",
    "\n",
    "            # переместим наш фрейм в csv-формат\n",
    "            #locals()[\"df\" + str(i)].to_csv('/work/ML_PHRASES/DataFrame от {0}.csv'.format(locals()[\"df\" + str(i)]['call_id'].unique()), encoding = 'utf-8', index = False, sep = ';')\n",
    "            \n",
    "            dfs_all.append(locals()[\"df\" + str(i)])\n",
    "\n",
    "\n",
    "            #print(locals()[\"df\" + str(i)])\n",
    "            #print('\\n\\n ПЕРЕХОД\\n')\n",
    "            \n",
    "           \n",
    "            # удаляем наши фреймы, чтобы освободить память\n",
    "            del locals()[\"df\" + str(i)]\n",
    "            del locals()[\"df_employee\" + str(i)]\n",
    "            del locals()[\"df_client\" + str(i)]\n",
    "            del locals()[\"df_itog\" + str(i)]\n",
    "            del locals()[\"df_last\" + str(i)]\n",
    "            del locals()[\"df_last_loc_cl\" + str(i)]\n",
    "            del locals()[\"df_last_loc_emp\" + str(i)]\n",
    "            \n",
    "            del locals()[\"x_cl\" + str(i)]\n",
    "            del locals()[\"words_cl\" + str(i)]\n",
    "            \n",
    "            del locals()[\"xmlData_employee\" + str(i)]  \n",
    "            del locals()[\"xmlData_client\" + str(i)]\n",
    "            del locals()[\"WordText_employee\" + str(i)]\n",
    "            del locals()[\"WordText_client\" + str(i)]\n",
    "            del locals()[\"StartMst_employee\" + str(i)]\n",
    "            del locals()[\"StartMst_client\" + str(i)]\n",
    "            del locals()[\"EndMs_employee\" + str(i)]\n",
    "            del locals()[\"EndMs_client\" + str(i)]\n",
    "            del locals()[\"hum_dttm_employee\" + str(i)]\n",
    "            del locals()[\"hum_dttm_client\" + str(i)]\n",
    "            \n",
    "            del locals()[\"hum_dttm_emp\" + str(i)]\n",
    "            del locals()[\"StartMst_emp\" + str(i)]\n",
    "            del locals()[\"EndMs_empl\" + str(i)]\n",
    "            del locals()[\"hum_dttm_cl\" + str(i)]\n",
    "            del locals()[\"StartMst_cl\" + str(i)]\n",
    "            del locals()[\"EndMs_cl\" + str(i)]\n",
    "            del locals()[\"index_true_emp\" + str(i)]\n",
    "            del locals()[\"index_false_emp\" + str(i)]\n",
    "            del locals()[\"index_true_cl\" + str(i)]\n",
    "            del locals()[\"index_false_cl\" + str(i)]\n",
    "            \n",
    "            del locals()[\"df_words_emp\" + str(i)]\n",
    "            del locals()[\"df_hum_sec_emp\" + str(i)]\n",
    "            del locals()[\"df_hum_dttm_emp\" + str(i)]\n",
    "            del locals()[\"df_start_sec_emp\" + str(i)]\n",
    "            \n",
    "            del locals()[\"df_words_cl\" + str(i)]\n",
    "            del locals()[\"df_hum_sec_cl\" + str(i)]\n",
    "            del locals()[\"df_hum_dttm_cl\" + str(i)]\n",
    "            del locals()[\"df_start_sec_cl\" + str(i)]\n",
    "            \n",
    "            del (df['result_1'][i])\n",
    "            del (df['result_0'][i])\n",
    "            #del df\n",
    "                       \n",
    "            \n",
    "            # собираем весь мусор\n",
    "            gc.collect()\n",
    "            \n",
    "            \n",
    "            \n",
    "            #locals()[\"df\" + str(i)].drop(locals()[\"df\" + str(i)].index, axis = 0, inplace=True)\n",
    "            goods.append(i)\n",
    "            #print(locals()[\"df\" + str(i)])\n",
    "        except:\n",
    "            #print('\\033[1m' + 'Ошибка в цикле!\\n' + '\\033[0m')\n",
    "            errors.append(i)\n",
    "            \n",
    "            \n",
    "    return dfs_all        \n",
    "    print('\\n Успешно загруженных: ' + str(len(goods)) + '\\n')\n",
    "    print('\\n Ошибок: ' + str(len(errors)) + '\\n')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отчищаем папочку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отчищаем папку с файлами\n",
    "import glob\n",
    "\n",
    "for i in glob.glob(\"/work/ML_PHRASES/*.csv\"):\n",
    "    os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускаем нашу основную функцию, на которую смотрит планировщик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import contextlib\n",
    "import ibis \n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "from IPython.core.display import display, HTML\n",
    "from hdfs.ext.kerberos import KerberosClient\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "\n",
    "def our_func_action():\n",
    "    \n",
    "    \n",
    "    print('\\nНачало выполнения запроса:', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '\\n')\n",
    "\n",
    "    # Строка подключения к БД\n",
    "    conn = connect(host = 'hdp-p3pml', \n",
    "                   port = 21050,  \n",
    "                   use_ssl = 'true', \n",
    "                   auth_mechanism = 'GSSAPI')\n",
    "\n",
    "    # Создание курсора, который выполнит запросы к БД\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"Set Mem_Limit = 30G\") # Запрос на расширение памяти\n",
    "\n",
    "    #cursor.execute('''SELECT t2.callid, now() as insertutcdate, t2.starttime, SPLIT_PART(t2.result, 'ChannelNum=\"1\"', 1) as result_0, SPLIT_PART(t2.result, 'ChannelNum=\"1\"', 2) as result_1 FROM dm_smartlogger.calls t1 JOIN dm_smartlogger.callresult t2 on (t1.callid = t2.callid) WHERE (from_timestamp(cast(t1.insertutcdate as TIMESTAMP), 'yyyy-MM-dd')) = (to_date(now() - interval 1 days)) and (from_timestamp(cast(t2.insertutcdate as TIMESTAMP), 'yyyy-MM-dd')) = (to_date(now() - interval 1 days)) and t1.CallDirection = 1 LIMIT 5''')\n",
    "    #df = pd.DataFrame(cursor.fetchall())\n",
    "\n",
    "    cursor.execute('''\n",
    "    SELECT DISTINCT\n",
    "       t2.callid, now() as insertutcdate, \n",
    "       t2.starttime, \n",
    "       SPLIT_PART(t2.result, 'ChannelNum=\"1\"', 1) as result_0, \n",
    "       SPLIT_PART(t2.result, 'ChannelNum=\"1\"', 2) as result_1\n",
    "FROM dm_smartlogger.calls t1 \n",
    "JOIN dmcparb.call_center_activity t3 \n",
    "  ON   ((substring(t1.RemotePhoneNumber, length(t1.RemotePhoneNumber)-9, 12)) = t3.contact_data\n",
    "               AND t1.CallDirection = 1\n",
    "               AND t3.sogl = 1\n",
    "       )\n",
    "JOIN dm_smartlogger.callresult t2 \n",
    "  ON (t1.callid = t2.callid \n",
    " AND (from_timestamp(cast(t1.insertutcdate as TIMESTAMP), 'yyyy-MM-dd')) = (to_date(now() - interval 1 days)) \n",
    " AND (from_timestamp(cast(t2.insertutcdate as TIMESTAMP), 'yyyy-MM-dd')) = (to_date(now() - interval 1 days))\n",
    "     )\n",
    "                  ''')\n",
    "     df = pd.DataFrame(cursor.fetchall())\n",
    "    \n",
    "    \n",
    "    print('\\nКонец выполнения запроса:', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '\\n')\n",
    "\n",
    "    # смотрим размер фрейма\n",
    "    print('\\033[1m' + 'Размер DataFrame составляет: {0} строк\\n'.format(df.shape[0]) + '\\033[0m')\n",
    "    print('\\033[1m' + '\\nОбъём занимаемой памяти:' + str((sys.getsizeof(df)*0.00000095)) + ' Mb\\n' + '\\033[0m')\n",
    "\n",
    "    # переименовывем колонки\n",
    "    df.columns = ['callid', 'insertutcdate','starttime', 'result_0', 'result_1']\n",
    "    df_new = df\n",
    "\n",
    "\n",
    "\n",
    "    print('\\nНачало отработки функции:', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '\\n')\n",
    "\n",
    "    # вызываем функцию для обработки фрейма\n",
    "    dfs_all = obrabotka(df_new)\n",
    "\n",
    "    df_new = pd.concat(dfs_all)\n",
    "    df_new.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    print('\\nКонец отработки функции:', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + '\\n')\n",
    "\n",
    "\n",
    "    # скидываем все данные в CSV\n",
    "    df_new = df_new[['call_id', 'phrase', 'who', 'start_dttm', 'dlitelnost_phrase_sec', 'dlitelnost_phrase']]\n",
    "\n",
    "    df_new.to_csv(\"/work/ML_FINAL/Final_phrases.csv\", index = False, encoding = 'utf-8', sep = ';')\n",
    "\n",
    "    \n",
    "    # загрузка данных в Hadoop \n",
    "    warnings.filterwarnings('ignore')\n",
    "    pd.set_option('max_columns', None)\n",
    "    display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "    # Считывание всех файлов из указанной папки\n",
    "    files = []\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        full_path = os.path.join(folder, file)\n",
    "        if os.path.isfile(full_path):\n",
    "            files.append(file)\n",
    "\n",
    "    print('\\nКол-во файлов в папке: ' + str(len(files)) + '\\n')\n",
    "\n",
    "    # Поиск строк с ошибочными разделителями\n",
    "    print('Начало анализа:', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "    with open('log.txt', 'w') as log:\n",
    "        # print записывает имя файла в лог\n",
    "        with contextlib.redirect_stdout(log):\n",
    "            # Если есть ошибка в разметке, она запишется в лог\n",
    "            with contextlib.redirect_stderr(log):\n",
    "                for file in sorted(files):\n",
    "                    print('Файл:', file)\n",
    "                    df = pd.read_csv(folder + '/' + file, sep = sep, encoding = 'utf-8', error_bad_lines = False, dtype = np.str)\n",
    "\n",
    "    print ('Конец анализа: ', datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "            # Загружаем лог для анализа\n",
    "    with open('log.txt', 'r') as log:\n",
    "        log_data = log.read()[:-1]\n",
    "\n",
    "    log_data = log_data.replace(\"'\\nb'\", \"\")       \n",
    "    log_data = log_data.replace(\"\\\\n\", \"; \")    \n",
    "\n",
    "    # Преобразуем его в DataFrame для удобства\n",
    "    df_log = pd.DataFrame(log_data.split('\\n'))\n",
    "\n",
    "    # Удаляем строки, по которым нет ошибок\n",
    "    df_log_error = pd.concat([df_log.shift(periods = 1, fill_value = 0), df_log], axis = 1)[1:]\n",
    "    df_log_error.columns = ['data', 'shift_data']\n",
    "    df_log_error['shift_data_index'] = df_log_error['shift_data'].str.find('Файл')\n",
    "    df_log_error = df_log_error[df_log_error['shift_data_index'] < 0]\n",
    "    df_log_error.drop(['shift_data_index'], inplace = True, axis = 1)\n",
    "\n",
    "    # Разбиение DataFrame в случае нескольких ошибок для одной строки\n",
    "    df_log_error['shift_data'] = df_log_error['shift_data'].str[2:-3]\n",
    "    df_log_error = df_log_error.set_index(['data']).apply(lambda x: x.str.split('; ').explode()).reset_index()\n",
    "    df_log_error['data'] = df_log_error['data'].str.replace('Файл: ', '')\n",
    "    df_log_error.columns = ['file_name', 'error']\n",
    "\n",
    "    df_log_error\n",
    "\n",
    "    for index, file in enumerate(sorted(files), 1):\n",
    "\n",
    "        # Вывод даты начала загрузки\n",
    "        start = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print('Начало загрузки: ' + start + ', файл: ' + str(index) + \". \" + file)\n",
    "\n",
    "        # Загрузка файла в память\n",
    "        df_for_load = pd.read_csv(folder + '/' + file, sep = sep, encoding = 'utf-8', dtype = np.str)\n",
    "        df_for_load['file_name'] = file\n",
    "\n",
    "\n",
    "        # Сколько записей считано в файле\n",
    "        print('Считано записей: ' + str(df_for_load.shape[0]))\n",
    "\n",
    "        # Подключение к БД для запросов\n",
    "        conn = connect(host = 'hdp-p3pml', \n",
    "                       port = 21050,  \n",
    "                       use_ssl = 'true', \n",
    "                       auth_mechanism = 'GSSAPI',\n",
    "                       database = database)\n",
    "        cursor = conn.cursor()  \n",
    "        cursor.execute(\"Drop Table If Exists \" + database + \".\" + temp_table)\n",
    "\n",
    "        # Загрузка данных во временную таблицу\n",
    "        file_schema = ibis.expr.schema.infer(df_for_load)\n",
    "        db_name = database\n",
    "        table_name = temp_table\n",
    "        impala_tbl_folder = '/data/sbx/' + database[database.find(\"_\") + 1:]\n",
    "        client = ibis.impala.connect(host = 'hdp-p3pml', \n",
    "                                     port = 21050,  \n",
    "                                     use_ssl = 'true', \n",
    "                                     auth_mechanism = 'GSSAPI')\n",
    "        db = client.database(db_name)\n",
    "        db.create_table(table_name, schema = file_schema)\n",
    "        df_for_load.to_parquet(table_name + '.parq', index = False)\n",
    "        client = KerberosClient('https://hdp-p3pml:14000')\n",
    "        client.upload(impala_tbl_folder + '/' + table_name + '/', table_name + '.parq')\n",
    "        db.table(table_name).refresh()\n",
    "\n",
    "        # Реально выполняется только для первого файла (из-за IF NOT EXISTS)\n",
    "        # Создание итоговой таблицы, структура которой соотвествует структуре временной\n",
    "        query = ''\n",
    "\n",
    "        cursor.execute(\"SHOW CREATE TABLE \" + database + '.' + temp_table)\n",
    "        query_result = cursor.fetchall()\n",
    "        for string in query_result:\n",
    "            str_beg = string[0].find('(')             # Оставляем запрос, начиная с первой скобки\n",
    "            str_end = string[0].find('PARQUET') + 7   # Обрезаем запрос до конца PARQUET\n",
    "            query += \"CREATE TABLE IF NOT EXISTS \" + database + '.' + table + \" \" + string[0][str_beg:str_end].replace('  ', '\\t')\n",
    "\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Перенос данных из временной таблицы\n",
    "        cursor.execute(\"Insert Into \" + database + \".\" + table + \" Select * From \" + database + \".\" + temp_table)\n",
    "\n",
    "        del df_for_load\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
